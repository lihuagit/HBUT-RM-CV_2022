

# 湖北工业大学 RoboMaster 2022赛季 视觉代码

本代码是湖北工业大学RoboMaster 2021赛季使用的视觉代码，在此向感谢上海交通大学（以下简称上交）！框架参考了上交2019年的开源代码，在此基础上我们依照实验室标准加入了串口协议、kalman滤波、预测方案。其中kalman参考了上交2021年的开源代码。

代码主要包括自瞄部分和能量机关部分，自瞄部分分为识别装甲板、角度结算、kalman预测。

本代码统一使用**640×480**大小的图像进行处理

| 作者   | 负责部分       | QQ         |
| ------ | -------------- | ---------- |
| 上交   | 整体框架       |            |
| 李华   | 自瞄装甲板识别 | 3190995951 |
| 崔金梦 | 能量机关识别   | 1425472943 |

**如有BUG或者想交流的朋友欢迎积极联系我们**

---

运行效果：自瞄帧率100（摄像头最大帧率）,识别距离根据环境不同大约8米左右(5mm焦距镜头)。

## 一、代码运行环境

| 硬件设备                                                     | 操作系统                                        | 运行库                                                       |
| ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |
| IntelNUC<br />MindVision工业相机MV-UBS31GC×１<br />USB转TTL×１ | Ubuntu20.04<br />Ubuntu18.04<br />Ｗindows10/11 | OpenCV4.5.4<br />OpenCV_contrib4.5.4<br />Eigen3<br />MindVision相机驱动 |

**实际装载在步兵和哨兵上的运行环境为Ubuntu20.04。**

相机驱动下载地址：[相机驱动](https://www.mindvision.com.cn)

OpenCV下载地址：[OpenCV](https://github.com/opencv)

OpenCV安装教程 : [linux](https://docs.opencv.org/4.5.4/d7/d9f/tutorial_linux_install.html)  [Windows](https://docs.opencv.org/4.5.4/d3/d52/tutorial_windows_install.html)

Eigen下载方法：
* Ubuntu20/18: ```sudo apt install libeigen3-dev```
* Windows10/11 : [Eigen下载地址](http://eigen.tuxfamily.org/)

GCC：

* Ubuntu20/18 : ```sudo apt install gcc g++```
* Windows10/11 : [MinGW](https://winlibs.com/)

## 二、程序编译运行以及调试方式

### 1.编译运行

* Ubuntu20/18（在项目文件夹下）

```shell
mkdir build
cd build
cmake ..
make -j8
sudo ./run
```

* Windows10

```shell
mkdir build
cd build
cmake ..
make -j8	# 或者是  mingw32-make -j8
sudo ./run
```

  

### 2.调试方式 -- 上交写的 不会用 但保留

```./run --help```可以查看所有命令行参数及其作用。所有调试选项都集成到了命令行参数中。

**不使用任何参数直接运行将没有任何图像显示。**

需要调参的部分：主要需要根据车辆情况而调参的参数存放在others/include/config/setconfig.h中

### 3.工作条件

* 对于自瞄，由于使用了数字识别，务必保证光照充足，图像上数字清晰可见。光照不足时，调整摄像头曝光或增益数值，直到数字清晰可见。
* 务必保证摄像头焦距正确，同时镜片干净无污物。
* 相机需要事先标定，并且标定数据更新在文件camera-param.yml中

## 三、文件目录结构（待更新）
```
.
├── armor                       // 存放自瞄主要算法代码
│   ├── include                 // 自瞄头文件
│   └── src                     // 自瞄源码
├── CMakeLists.txt              // cmake工程文件
├── energy                      // 存放能量机关主要算法代码
│   ├── include                 // 能量机关头文件
│   └── src                     // 能量机关源码
├── main.cpp                    // 主函数
├── others                      // 存放摄像头、串口、配置文件等
│   ├── include                 // others头文件
│   ├── libmvsdk.dylib          // mac相机驱动链接库
│   ├── libMVSDK.so             // linux相机驱动链接库
│   ├── MVCAMSDK_X64.dll        // win10相机驱动链接库
│   ├── MV-UB31-Group0.config   // 相机配置文件
│   └── src                     // others源码
└── tools                       // 存放分类器训练代码及参数，自启动脚步等
    ├── auto-pull.sh            // 自动代码更新脚本
    ├── create-startup.sh       // 自启动文件创建脚本
    ├── monitor.bat             // win10进程守护脚本
    ├── monitor.sh              // linux进程守护脚本
    ├── para                    // 分类器参数
    └── TrainCNN                // 分类器训练源码
```
## 四、关键类解析

| 类名            | 主要成员                                                     | 主要接口               | 类的作用                                                |
| --------------- | ------------------------------------------------------------ | ---------------------- | ------------------------------------------------------- |
| ArmorFinder     | 过多，不做赘述                                               | void run(cv::Mat &src) | 将一帧图像中装甲板的detection以及数据发送封装为一个类   |
| Energy          | 过多，不做赘述                                               | void run(cv::Mat &src) | 将一帧图像中能量机关的detection以及数据发送封装为一个类 |
| EnergyPartParam | 过多，不做赘述                                               | 无                     | 能量机关所有参数的集合                                  |
| LightBlob       | 灯条位置<br />灯条颜色                                   | 无                     | 灯条类定义                                              |
| ArmorBox        | 装甲板位置<br />装甲板的两个灯条<br />装甲板颜色<br />装甲板数字id | 无                     | 装甲板类定义                                            |

## 五、程序运行基本流程
![HBUT-RM2022代码流程图](https://github.com/lihuagit/SJTU-RM-CV-2019/HBUT-RM2022%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

## 六、识别方式

### 1.自瞄装甲板识别方式

* 预处理
  * 首先对图像进行通道拆分以，按照颜色进行二值化操作，再进行开闭运算
  * 通过边缘提取和条件限制得出可能为灯条的部分
* 匹配装甲板
  * 对所有可能的灯条进行两两匹配，根据形状大小角度等特性进行筛选，得到装甲板的候选区
  * 把所有候选区交给分类器判断，得出真实的装甲板及其数字id
  * 根据优先级选取最终击打目标以及后续处理
* 角度结算
  * 使用solvePnP函数对装甲板位姿进行结算出相对坐标
* 预测
  * 将solvePnP结算获得的装甲板位姿通过电控传来的数据转化为世界坐标
  * 将世界坐标使用kalman进行滤波
  * 使用kalman处理的滤波值和速度对装甲板进行预测
* 发送
  * 将处理好的数据使用预先设计好的协议通过串口发送给电控
* 接收
  * 这是一个单独的线程，一直接收电控传来的数据

#### 1.1 预测

我们假设车辆在较短的时间内的运动都是匀速直线运动模型，模型公式如下：

![ekf_model](C:\Users\31909\Desktop\ekf_model.png)

其中 z 轴假设不变，之后也可以尝试改成变的，对爬坡可能有帮助。

### 2.能量机关识别方式

​    首先对图像进行二值化操作，然后进行一定腐蚀和膨胀，通过边缘提取和条件限制得出待击打叶片（锤子形）。在待击打叶片范围内进一步用类似方法寻找目标装甲板和流动条，在二者连线上寻找中心的“R”。根据目标装甲板坐标和中心坐标计算极坐标系下的目标角度，进而预测待击打点的坐标（小符为装甲板本身，大符需要旋转）。最后将待击打点坐标和图像中心的差值转换为yaw和pitch轴角度，增加一环PID后发送给云台主控板。

## 七、通信协议

### 1.通信方式

使用USB转TTL进行串口通信

### 2.1 状态结构体

```c++
struct McuData {
    float curr_yaw;      // 当前云台yaw角度
    float curr_pitch;    // 当前云台pitch角
    uint8_t state;       // 当前状态，自瞄-大符-小符
    uint8_t mark;        // 云台角度标记位
    uint8_t anti_top;    // 是否为反陀螺模式
    uint8_t enemy_color; // 敌方颜色
    int delta_x;         // 能量机关x轴补偿量
    int delta_y;         // 能量机关y轴补偿量
};
```
### 2.2 数据接收结构体

```c++
struct RecData{
	char mode;			// 当前状态，自瞄-大符-小符
    char mode_shoot;	// 射速
    float word_yaw;		// 当前云台yaw角度
    float word_pitch;	// 当前云台pitch角度
}
```

实际发送代码中没有使用这个结构体，而是使用uint8_t类型数组直接赋值代替

### 3.数据发送结构体

```c++
struct SendData {
    char start_flag;      // 帧头标志，字符's'
    float yaw;          // float类型的实际角度弧度制
    float pitch;        // float类型的实际角度弧度制
    char end_flag;        // 帧尾标识，字符'e'
};
```

实际发送代码中没有使用这个结构体，而是使用uint8_t类型数组直接赋值代替

## 八、代码命名规范

函数名：使用首字母小写的驼峰命名法

类型名：使用首字母大写的驼峰命名法

变量名：使用下划线分割命名法

 可能存在部分命名不规范

## 九、未来的优化方向
* 图像的预处理部分做的不是很好，还是会存在误识别的情况，虽然会在后面的处理中被过滤掉，但这会增大后面的计算量。
* 代码中使用CNN分类器对灯条候选区进行筛选以及数字识别，但分类器总是不能做到100%的正确率，同时许多明显为背景的候选区有时也会被误判成装甲板，导致误识别。**所以第二个优化方向是更低的误识别率(可以从候选区生成入手或者从分类器入手)**，这里我们将会尝试使用opencv自带的深度学习进行数字识别，并且将改掉之前的策略，灯条不参与识别，只识别数字，以为预处理不可靠的原因，现在的代码使用CNN分类器时会将灯条一起识别，在预处理可靠的情况下，是可以做到只对数字进行识别的，这会大大增大识别率。
* 由于陀螺这样的机械设计基本上是强队的标准配置，所以我们也首次尝试了从视觉层面对陀螺有一个专门的击打方式，我们目前没有对于的反陀螺策略，让操作手使用不预测模式任意发挥，使用效果不好。**所以第三个优化方向便是一个有着自动击打动态陀螺的系统**。
